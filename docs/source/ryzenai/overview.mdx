<!--Copyright 2023 The HuggingFace Team. All rights reserved.
Licensed under the MIT License.
-->

# AMD Ryzen AI

<Tip>

Ryzen AI support is work in progress and will greatly be improved and extended in the coming months.

</Tip>

AMD's Ryzen™ AI family of laptop processors provide users with an integrated Neural Processing Unit (NPU) which offloads the host CPU and GPU from AI processing tasks. Ryzen™ AI software consists of the Vitis™ AI execution provider (EP) for ONNX Runtime combined with quantization tools and a [pre-optimized model zoo](https://huggingface.co/models?other=RyzenAI). All of this is made possible based on Ryzen™ AI technology built on AMD XDNA™ architecture, purpose-built to run AI workloads efficiently and locally, offering a host of benefits for the developer innovating the next groundbreaking AI app.

Optimum-AMD provides easy interface for loading and inference of Hugging Face models on Ryzen AI accelerator.

## Ryzen AI Environment setup

A Ryzen AI environment needs to be enabled to use this library. Please refer to Ryzen AI's [Installation](https://ryzenai.docs.amd.com/en/latest/inst.html) and [Runtime Setup](https://ryzenai.docs.amd.com/en/latest/runtime_setup.html).

Note:
The RyzenAI Model requires a runtime configuration file. A default version of this runtime configuration file can be found in the voe-4.0-win_amd64 folder of the Ryzen AI Software installation package under the name vaip_config.json.
For more information refer to [runtime-configuration-file](https://ryzenai.docs.amd.com/en/latest/runtime_setup.html#runtime-configuration-file)

## Minimal working example

To load a model and run inference with RyzenAI, you can just replace your `AutoModelForXxx` class with the corresponding `RyzenAIModelForXxx` class.


```python
import requests
from PIL import Image

from optimum.amd.ryzenai import RyzenAIModelForImageClassification
from transformers import AutoFeatureExtractor, pipeline

url = "http://images.cocodataset.org/val2017/000000039769.jpg"
image = Image.open(requests.get(url, stream=True).raw)

model_id = <path of the model>

# The path and name of the runtime configuration file. A default version of this file can be
# found in the voe-4.0-win_​amd64 folder of the Ryzen AI software installation package under
# the name vaip_​config.json
vaip_config = <path of the config file>

model = RyzenAIModelForImageClassification.from_pretrained(model_id, vaip_config=vaip_config)
feature_extractor = AutoFeatureExtractor.from_pretrained(model_id)
cls_pipe = pipeline("image-classification", model=model, feature_extractor=feature_extractor)
outputs = cls_pipe(image)
```

## Inference with [pre-optimized models](https://huggingface.co/models?other=RyzenAI)

RyzenAI provides pre-optimized models for various tasks such as image classification, super-resolution, object-detection, etc. Here's an example to run Resnet for image classification:

```python
from datasets import load_dataset

from optimum.amd.ryzenai import RyzenAIModelForImageClassification
from transformers import AutoImageProcessor

model_id = 'amd/resnet50'
model = RyzenAIModelForImageClassification.from_pretrained(
    model_id,
    file_name="ResNet_int.onnx",
    vaip_config='vaip_config.json',
)
dataset = load_dataset("huggingface/cats-image")
image = dataset["test"]["image"][0]

processor = AutoImageProcessor.from_pretrained("microsoft/resnet-50")
inputs = processor(image, return_tensors="pt")
logits = model(**inputs).logits

predicted_label = logits.argmax(-1).item()
```